================================================================
Repository Files
================================================================

================
File: schema/seqspec.schema.json
================
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "Assay.schema.json",
  "title": "Assay",
  "description": "A Assay of DNA",
  "type": "object",
  "properties": {
    "seqspec_version": {
      "description": "Version of the seqspec specification used",
      "type": "string",
      "pattern": "^(0|[1-9]\\d*)\\.(0|[1-9]\\d*)\\.(0|[1-9]\\d*)(?:-((?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\.(?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))?(?:\\+([0-9a-zA-Z-]+(?:\\.[0-9a-zA-Z-]+)*))?$"
    },
    "assay_id": {
      "description": "Identifier for the assay",
      "type": "string"
    },
    "name": {
      "description": "The name of the assay",
      "type": "string"
    },
    "doi": {
      "description": "the doi of the paper that describes the assay",
      "type": "string"
    },
    "date": {
      "description": "The seqspec creation date",
      "type": "string",
      "pattern": "^(0?[1-9]|[12][0-9]|3[01])\\s(January|February|March|April|May|June|July|August|September|October|November|December)\\s(19|20)\\d\\d$"
    },
    "description": {
      "description": "A short description of the assay",
      "type": "string"
    },
    "modalities": {
      "description": "The modalities the assay targets",
      "type": "array",
      "items": {
        "type": "string",
        "enum": ["dna", "rna", "tag", "protein", "atac", "crispr"]
      }
    },
    "lib_struct": {
      "description": "The link to Teichmann's libstructs page derived for this sequence",
      "type": "string"
    },
    "library_protocol": {
      "description": "The protocol/machine/tool to generate the library insert",
      "type": "string"
    },
    "library_kit": {
      "description": "The kit used to make the library sequence_protocol compatible",
      "type": "string"
    },
    "sequence_protocol": {
      "description": "The protocol/machine/tool to generate sequences",
      "type": "string"
    },
    "sequence_kit": {
      "description": "The kit used with the protocol to sequence the library",
      "type": "string"
    },
    "sequence_spec": {
      "description": "The spec for the sequencer",
      "type": "array",
      "items": {
        "$ref": "#/$defs/read"
      }
    },
    "library_spec": {
      "description": "The spec for the assay",
      "type": "array",
      "items": {
        "$ref": "#/$defs/region"
      }
    }
  },
  "required": [
    "seqspec_version",
    "assay_id",
    "name",
    "doi",
    "date",
    "description",
    "modalities",
    "lib_struct",
    "library_protocol",
    "library_kit",
    "sequence_protocol",
    "sequence_kit"
  ],
  "$defs": {
    "region": {
      "title": "Region",
      "description": "A region of DNA",
      "type": "object",
      "properties": {
        "region_id": {
          "description": "identifier for the region",
          "type": "string"
        },
        "region_type": {
          "description": "the type of region",
          "type": "string",
          "enum": [
            "atac",
            "barcode",
            "cdna",
            "crispr",
            "custom_primer",
            "dna",
            "fastq",
            "fastq_link",
            "gdna",
            "hic",
            "illumina_p5",
            "illumina_p7",
            "index5",
            "index7",
            "linker",
            "ME1",
            "ME2",
            "methyl",
            "named",
            "nextera_read1",
            "nextera_read2",
            "poly_A",
            "poly_G",
            "poly_T",
            "poly_C",
            "protein",
            "rna",
            "s5",
            "s7",
            "tag",
            "truseq_read1",
            "truseq_read2",
            "umi"
          ]
        },
        "sequence_type": {
          "description": "The type of the sequence",
          "type": "string",
          "enum": ["fixed", "random", "onlist", "joined"]
        },
        "sequence": {
          "description": "The sequence",
          "type": "string",
          "pattern": "^[ACGTRYMKSWHBVDNX]+$"
        },
        "min_len": {
          "description": "The minimum length of the sequence",
          "type": "integer",
          "minimum": 0,
          "maximum": 2048
        },
        "max_len": {
          "description": "The maximum length of the sequence",
          "type": "integer",
          "minimum": 0,
          "maximum": 2048
        },
        "onlist": {
          "description": "The file containing the sequence if seq_type = onlist",
          "type": ["object", "null"],
          "properties": {
            "location": {
              "description": "location of onlist",
              "type": "string",
              "enum": ["local", "remote"]
            },
            "filename": {
              "description": "filename for the onlist",
              "type": "string"
            },
            "md5": {
              "description": "md5sum for the file pointed to by filename",
              "type": "string",
              "pattern": "^[a-f0-9]{32}$"
            }
          }
        },
        "regions": {
          "description": "The regions being joined",
          "type": "array",
          "items": {
            "$ref": "#/$defs/region"
          }
        }
      },
      "required": [
        "region_id",
        "region_type",
        "sequence_type",
        "sequence",
        "min_len",
        "max_len"
      ]
    },
    "read": {
      "title": "Read",
      "type": "object",
      "properties": {
        "read_id": {
          "type": "string",
          "description": "The unique identifier for the read."
        },
        "name": {
          "type": "string",
          "description": "The name of the read."
        },
        "modality": {
          "type": "string",
          "description": "The modality of the assay generating the read."
        },
        "primer_id": {
          "type": "string",
          "description": "The region id of the primer used."
        },
        "min_len": {
          "type": "integer",
          "minimum": 0,
          "description": "The minimum length of the read, must be greater than or equal to 0."
        },
        "max_len": {
          "type": "integer",
          "exclusiveMinimum": 0,
          "description": "The maximum length of the read, must be greater than 0."
        },
        "strand": {
          "type": "string",
          "enum": ["pos", "neg"],
          "description": "The strand orientation of the read, either positive ('pos') or negative ('neg')."
        }
      },
      "required": [
        "read_id",
        "modality",
        "primer_id",
        "min_len",
        "max_len",
        "strand"
      ],
      "additionalProperties": false
    }
  }
}

================
File: __init__.py
================
__version__ = "0.2.0"

================
File: Assay.py
================
import yaml
from seqspec.Region import Region, Read
from typing import List
import json
from . import __version__


class Assay(yaml.YAMLObject):
    yaml_tag = "!Assay"

    def __init__(
        self,
        assay_id: str,
        name: str,
        doi: str,
        date: str,
        description: str,
        modalities: List[str],
        lib_struct: str,
        sequence_protocol: str,
        sequence_kit: str,
        library_protocol: str,
        library_kit: str,
        sequence_spec: List[Read],
        library_spec: List[Region],
        seqspec_version: str = __version__,
    ) -> None:
        super().__init__()
        self.seqspec_version = seqspec_version
        self.assay_id = assay_id
        self.name = name
        self.doi = doi
        self.date = date
        self.description = description
        self.modalities = modalities
        self.lib_struct = lib_struct
        self.sequence_protocol = sequence_protocol
        self.sequence_kit = sequence_kit
        self.library_protocol = library_protocol
        self.library_kit = library_kit
        self.sequence_spec = sequence_spec
        self.library_spec = library_spec

    def __repr__(self) -> str:
        d = {
            "seqspec_version": self.seqspec_version,
            "assay_id": self.assay_id,
            "name": self.name,
            "doi": self.doi,
            "date": self.date,
            "description": self.description,
            "modalities": self.modalities,
            "lib_struct": self.lib_struct,
            "sequence_protocol": self.sequence_protocol,
            "sequence_kit": self.sequence_kit,
            "library_protocol": self.library_protocol,
            "library_kit": self.library_kit,
            "sequence_spec": self.sequence_spec,
            "library_spec": self.library_spec,
        }
        return f"{d}"

    def to_dict(self):
        d = {
            "seqspec_version": self.seqspec_version,
            "assay_id": self.assay_id,
            "name": self.name,
            "doi": self.doi,
            "date": self.date,
            "description": self.description,
            "modalities": self.modalities,
            "lib_struct": self.lib_struct,
            "sequence_protocol": self.sequence_protocol,
            "sequence_kit": self.sequence_kit,
            "library_protocol": self.library_protocol,
            "library_kit": self.library_kit,
            "sequence_spec": [o.to_dict() for o in self.sequence_spec],
            "library_spec": [o.to_dict() for o in self.library_spec],
        }
        return d

    def to_JSON(self):
        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=False, indent=4)

    # note to_yaml is reserved for yaml.YAMLObject
    def to_YAML(self, fname: str):
        with open(fname, "w") as f:
            yaml.dump(self, f, sort_keys=False)

    def print_sequence(self):
        for region in self.library_spec:
            print(region.get_sequence(), end="")
        print("\n", end="")

    def update_spec(self):
        for r in self.library_spec:
            r.update_attr()

    def get_libspec(self, modality):
        return self.library_spec[self.modalities.index(modality)]

    def get_seqspec(self, modality):
        return [r for r in self.sequence_spec if r.modality == modality]

    def get_read(self, read_id):
        return [r for r in self.sequence_spec if r.read_id == read_id][0]

    def list_modalities(self):
        return self.modalities

================
File: main.py
================
from . import __version__
import argparse
import sys
from .seqspec_format import setup_format_args, validate_format_args
from .seqspec_print import setup_print_args, validate_print_args
from .seqspec_check import setup_check_args, validate_check_args
from .seqspec_find import setup_find_args, validate_find_args

from .seqspec_genbank import setup_genbank_args, validate_genbank_args
from .seqspec_modify import setup_modify_args, validate_modify_args
from .seqspec_index import setup_index_args, validate_index_args
from .seqspec_info import setup_info_args, validate_info_args

from .seqspec_split import setup_split_args, validate_split_args
from .seqspec_init import setup_init_args, validate_init_args
from .seqspec_onlist import setup_onlist_args, validate_onlist_args
from .seqspec_version import setup_version_args, validate_version_args

# Steps to add new subcommands
# Create seqspec_subcommand.py (create setup_subcmd_args, validate_subcmd_args, run_subcmd in that file)
# (in this file) from seqspec_subcmd import setup_subcmd_args, validate_subcmd_args
# Add setup_subcmd_args to command_to_parser along with its key==str(subcmd)
# Add validate_subcmd_args to COMMAND_TO_FUNCTION along with its key==str(subcmd)


def main():
    # setup parsers
    parser = argparse.ArgumentParser(
        description=f"seqspec {__version__}: Format sequence specification files"
    )

    subparsers = parser.add_subparsers(
        dest="command",
        metavar="<CMD>",
    )

    # Setup the arguments for all subcommands
    command_to_parser = {
        "check": setup_check_args(subparsers),
        "find": setup_find_args(subparsers),
        "format": setup_format_args(subparsers),
        "genbank": setup_genbank_args(subparsers),
        "index": setup_index_args(subparsers),
        "info": setup_info_args(subparsers),
        "init": setup_init_args(subparsers),
        "modify": setup_modify_args(subparsers),
        "onlist": setup_onlist_args(subparsers),
        "print": setup_print_args(subparsers),
        "split": setup_split_args(subparsers),
        "version": setup_version_args(subparsers),
    }
    # Show help when no arguments are given
    if len(sys.argv) == 1:
        parser.print_help(sys.stderr)
        sys.exit(1)
    if len(sys.argv) == 2:
        if sys.argv[1] in command_to_parser:
            command_to_parser[sys.argv[1]].print_help(sys.stderr)
        elif sys.argv[1] == "--version":
            print(f"seqspec {__version__}")
        else:
            parser.print_help(sys.stderr)
        sys.exit(1)

    args = parser.parse_args()

    # Setup validator and runner for all subcommands (validate and run if valid)
    COMMAND_TO_FUNCTION = {
        "format": validate_format_args,
        "print": validate_print_args,
        "check": validate_check_args,
        "find": validate_find_args,
        "index": validate_index_args,
        "info": validate_info_args,
        "init": validate_init_args,
        "modify": validate_modify_args,
        "onlist": validate_onlist_args,
        "split": validate_split_args,
        "version": validate_version_args,
        "genbank": validate_genbank_args,
    }
    COMMAND_TO_FUNCTION[sys.argv[1]](parser, args)


if __name__ == "__main__":
    main()

================
File: Region.py
================
from typing import Optional, List
import yaml


# todo figure out how to do enums type options
class Region(yaml.YAMLObject):
    yaml_tag = "!Region"

    def __init__(
        self,
        region_id: str,
        region_type: str,
        name: str,
        sequence_type: str,
        sequence: str = "",
        min_len: int = 0,
        max_len: int = 1024,
        onlist: Optional["Onlist"] = None,
        regions: Optional[List["Region"]] = None,
    ) -> None:
        super().__init__()
        self.parent_id = None
        self.region_id = region_id
        self.region_type = region_type
        self.name = name
        self.sequence_type = sequence_type
        self.sequence = sequence

        self.min_len = min_len
        self.max_len = max_len

        self.onlist = onlist
        self.regions = regions

        if self.regions:
            self.min_len, self.max_len = self.get_len()

            self.sequence = self.get_sequence()

    def set_parent_id(self, parent_id):
        self.parent_id = parent_id
        if self.regions:
            parent_id = self.region_id
            for r in self.regions:
                r.set_parent_id(parent_id)

    def get_sequence(self, s: str = "") -> str:
        if self.regions:
            for r in self.regions:
                s = r.get_sequence(s)
        else:
            if self.sequence:
                s += self.sequence
            elif self.sequence is None:
                s += "X"
        return s

    def get_len(self, min_l: int = 0, max_l: int = 0):
        if self.regions:
            for r in self.regions:
                min_l, max_l = r.get_len(min_l, max_l)
        else:
            min_l += self.min_len
            max_l += self.max_len
        return (min_l, max_l)

    def get_onlist(self):
        return self.onlist

    def update_attr(self):
        if self.regions:
            for idx, r in enumerate(self.regions):
                r.update_attr()

        self.sequence = self.get_sequence()
        self.min_len, self.max_len = self.get_len()
        if self.sequence_type == "random":
            self.sequence = "X" * self.max_len
        if self.sequence_type == "onlist":
            self.sequence = "N" * self.max_len
        return

    def __repr__(self) -> str:
        d = {
            "region_id": self.region_id,
            "region_type": self.region_type,
            "name": self.name,
            "sequence_type": self.sequence_type,
            "onlist": self.onlist,
            "sequence": self.sequence,
            "min_len": self.min_len,
            "max_len": self.max_len,
            "regions": self.regions,
        }
        return f"{d}"

    def to_dict(self):
        d = {
            "region_id": self.region_id,
            "region_type": self.region_type,
            "name": self.name,
            "sequence_type": self.sequence_type,
            "onlist": self.onlist.to_dict() if self.onlist else None,
            "sequence": self.sequence,
            "min_len": self.min_len,
            "max_len": self.max_len,
            "regions": [i.to_dict() for i in (self.regions or [])],
        }
        return d

    def to_newick(self, n=""):
        if self.regions:
            t = []
            for r in self.regions:
                t.append(f"{r.to_newick(n)}")
                n = f"({','.join(t)}){r.parent_id}"
        else:
            n = f"'{self.region_id}:{self.max_len}'"

        return n

    def get_region_by_id(self, region_id, found=[]):
        if not found:
            found = []
        if self.region_id == region_id:
            found.append(self)
        if self.regions:
            for r in self.regions:
                found = r.get_region_by_id(region_id, found)
        return found

    def get_region_by_region_type(self, region_type, found=[]):
        if not found:
            found = []
        if self.region_type == region_type:
            found.append(self)
        if self.regions:
            for r in self.regions:
                found = r.get_region_by_region_type(region_type, found)
        return found

    def get_onlist_regions(self, found=[]):
        if not found:
            found = []
        if self.onlist is not None:
            found.append(self)
        if self.regions:
            for r in self.regions:
                found = r.get_onlist_regions(found)
        return found

    def get_leaves(self, leaves=[]):
        if not leaves:
            leaves = []
        if not self.regions:
            leaves.append(self)
        else:
            for r in self.regions:
                leaves = r.get_leaves(leaves=leaves)
        return leaves

    def get_leaf_region_types(self):
        leaves = self.get_leaves()
        rtypes = set()
        for r in leaves:
            rtypes.add(r.region_type)
        return rtypes

    # how do I make sure this updates the spec in place?

    def update_region(
        self,
        region_id,
        region_type,
        name,
        sequence_type,
        sequence,
        min_len,
        max_len,
        onlist,
    ):
        self.region_id = region_id
        self.region_type = region_type
        self.name = name
        self.sequence_type = sequence_type
        self.sequence = sequence
        self.min_len = min_len
        self.max_len = max_len
        self.onlist = onlist
        return

    def update_region_by_id(
        self,
        target_region_id,
        region_id,
        region_type,
        name,
        sequence_type,
        sequence,
        min_len,
        max_len,
    ):
        # Identify the target subregion
        target_region = self.get_region_by_id(target_region_id)
        if target_region:
            target_region = target_region[0]  # Assuming region_id is unique
            # Update the properties of the target subregion
            # check if not none
            if region_id:
                target_region.region_id = region_id
            if region_type:
                target_region.region_type = region_type
            if name:
                target_region.name = name
            if sequence_type:
                target_region.sequence_type = sequence_type
            if sequence:
                target_region.sequence = sequence
            if min_len:
                target_region.min_len = min_len
            if max_len:
                target_region.max_len = max_len
        return

    def reverse(self):
        if self.regions:
            # reverse the list of sub regions
            for r in self.regions[::-1]:
                r.reverse()
        else:
            # reverse the actual sequence
            self.sequence = self.sequence[::-1]
        return

    def complement(self):
        if self.regions:
            for r in self.regions:
                r.complement()
        else:
            self.sequence = complement_sequence(self.sequence)


def complement_nucleotide(nucleotide):
    complements = {
        "A": "T",
        "T": "A",
        "G": "C",
        "C": "G",
        "R": "Y",
        "Y": "R",
        "S": "S",
        "W": "W",
        "K": "M",
        "M": "K",
        "B": "V",
        "D": "H",
        "V": "B",
        "H": "D",
        "N": "N",
        "X": "X",
    }
    return complements.get(
        nucleotide, "N"
    )  # Default to 'N' if nucleotide is not recognized


def complement_sequence(sequence):
    return "".join(complement_nucleotide(n) for n in sequence.upper())


class RegionCoordinate(Region):
    def __init__(
        self,
        region: Region,
        start: int = 0,
        stop: int = 0,
    ):
        super().__init__(
            region.region_id,
            region.region_type,
            region.name,
            region.sequence_type,
            region.sequence,
            region.min_len,
            region.max_len,
            region.onlist,
            region.regions,
        )
        self.start = start
        self.stop = stop

    def __repr__(self):
        return f"RegionCoordinate {self.name} [{self.region_type}]: ({self.start}, {self.stop})"

    def __str__(self):
        return f"RegionCoordinate {self.name} [{self.region_type}]: ({self.start}, {self.stop})"

    def __eq__(self, other):
        return self.start == other.start and self.stop == other.stop


def project_regions_to_coordinates(
    regions: List[Region], rcs: List[RegionCoordinate] = []
) -> List[RegionCoordinate]:
    if not rcs:
        rcs = []
    prev = 0
    for r in regions:
        nxt = prev + r.max_len
        rc = RegionCoordinate(r, prev, nxt)
        rcs.append(rc)
        prev = nxt
    return rcs


def itx_read(
    region_coordinates: List[RegionCoordinate], read_start: int, read_stop: int
):
    # return a list of region_coordinates intersect with read start/stop
    new_rcs = []

    for idx, rc in enumerate(region_coordinates):
        # read start after rc ends, ignore
        if read_start >= rc.stop:
            continue
        # read stop before rc starts, ignore
        if read_stop <= rc.start:
            continue

        # all region_coordinates now have read start or stop in the rc

        # read start in rc, update start
        if read_start >= rc.start:
            rc.start = read_start
        # read stop in rc, update stop
        if read_stop < rc.stop:
            rc.stop = read_stop
        new_rcs.append(rc)

    return new_rcs


class Onlist(yaml.YAMLObject):
    yaml_tag = "!Onlist"

    def __init__(self, filename: str, md5: str, location: str) -> None:
        super().__init__()
        self.filename = filename
        self.md5 = md5
        self.location = location

    def __repr__(self) -> str:
        d = {
            "filename": self.filename,
            "location": self.location,
            "md5": self.md5,
        }
        return f"{d}"

    def to_dict(self):
        d = {
            "filename": self.filename,
            "location": self.location,
            "md5": self.md5,
        }
        return d


class Read(yaml.YAMLObject):
    yaml_tag = "!Read"

    def __init__(
        self,
        read_id: str,
        name: str,
        modality: str,
        primer_id: str,
        min_len: int,
        max_len: int,
        strand: str,
    ) -> None:
        super().__init__()
        self.read_id = read_id
        self.name = name
        self.modality = modality
        self.primer_id = primer_id
        self.min_len = min_len
        self.max_len = max_len
        self.strand = strand

    def __repr__(self) -> str:
        d = {
            "read_id": self.read_id,
            "name": self.name,
            "modality": self.modality,
            "primer_id": self.primer_id,
            "min_len": self.min_len,
            "max_len": self.max_len,
            "strand": self.strand,
        }
        return f"{d}"

    def to_dict(self):
        d = {
            "read_id": self.read_id,
            "name": self.name,
            "modality": self.modality,
            "primer_id": self.primer_id,
            "min_len": self.min_len,
            "max_len": self.max_len,
            "strand": self.strand,
        }
        return d




================
File: seqspec_find.py
================
from seqspec.utils import load_spec
from seqspec.Assay import Assay
import yaml


def setup_find_args(parser):
    subparser = parser.add_parser(
        "find",
        description="find regions in a seqspec file",
        help="find regions in a seqspec file",
    )
    subparser_required = subparser.add_argument_group("required arguments")

    subparser.add_argument("yaml", help="Sequencing specification yaml file")
    subparser.add_argument(
        "-o",
        metavar="OUT",
        help=("Path to output file"),
        type=str,
        default=None,
    )
    subparser.add_argument("--rtype", help="Find by region type", action="store_true")
    subparser_required.add_argument(
        "-m",
        metavar="MODALITY",
        help=("Modality"),
        type=str,
        default=None,
        required=True,
    )
    subparser_required.add_argument(
        "-r",
        metavar="REGION",
        help=("Region"),
        type=str,
        default=None,
        required=True,
    )

    return subparser


def validate_find_args(parser, args):
    # if everything is valid the run_find
    # get paramters
    fn = args.yaml
    m = args.m
    r = args.r
    o = args.o

    rt = args.rtype

    # load spec
    spec = load_spec(fn)

    # run function
    if rt:
        regions = run_find_by_type(spec, m, r)
    else:
        regions = run_find(spec, m, r)

    # post processing
    if o:
        with open(o, "w") as f:
            yaml.dump(regions, f, sort_keys=False)
    else:
        print(yaml.dump(regions, sort_keys=False))


def run_find(spec: Assay, modality: str, region_id: str):
    m = spec.get_libspec(modality)
    regions = m.get_region_by_id(region_id)
    return regions


def run_find_by_type(spec: Assay, modality: str, region_type: str):
    m = spec.get_libspec(modality)
    regions = m.get_region_by_region_type(region_type)
    return regions

================
File: seqspec_format.py
================
from seqspec.utils import load_spec


def setup_format_args(parser):
    subparser = parser.add_parser(
        "format",
        description="format seqspec file",
        help="format seqspec file",
    )
    subparser_required = subparser.add_argument_group("required arguments")

    subparser.add_argument("yaml", help="Sequencing specification yaml file")
    subparser_required.add_argument(
        "-o",
        metavar="OUT",
        help=("Path to output file"),
        type=str,
        default=None,
        required=True,
    )
    return subparser


def validate_format_args(parser, args):
    # if everything is valid the run_format
    fn = args.yaml
    o = args.o
    spec = load_spec(fn)
    run_format(spec)
    spec.to_YAML(o)


def run_format(spec):
    spec.update_spec()

================
File: seqspec_genbank.py
================
from seqspec.utils import load_genbank
import json
from seqspec.Region import Region
from seqspec.Assay import Assay


def setup_genbank_args(parser):
    subparser = parser.add_parser(
        "genbank",
        description="get genbank about seqspec file",
        help="get genbank about seqspec file",
    )

    subparser.add_argument("gbk", help="Genbank file")
    subparser.add_argument(
        "-o",
        metavar="OUT",
        help=("Path to output file"),
        type=str,
        default=None,
        required=False,
    )
    return subparser


def validate_genbank_args(parser, args):
    # if everything is valid the run_genbank
    fn = args.gbk
    o = args.o
    gb = load_genbank(fn)

    spec = run_genbank(gb)

    if o:
        spec.to_YAML(o)
    else:
        print(json.dumps(spec, sort_keys=False, indent=4))


def run_genbank(gb):
    ex = gb_to_list(gb)
    nested_json = nest_intervals(ex)
    filled_regions = fill_gaps(gb.sequence, nested_json)
    regions = convert(filled_regions)
    spec = Assay(
        "genbank",
        "illumina",
        "genbank thing",
        "doi",
        "date",
        "description",
        ["source"],
        "",
        regions,
    )
    return spec


def gb_to_list(gb):
    feat = []
    label = "source"
    for f in gb.features:
        id = f.key

        if "complement" in f.location:
            start, stop = tuple(map(int, f.location[11:-1].split("..")))
        else:
            start, stop = tuple(map(int, f.location.split("..")))

        # convert to 0-index
        start -= 1
        length = stop - start
        seq = gb.sequence[start:stop]

        for q in f.qualifiers:
            if q.key == "/label=":
                label = q.value
                break
        feat.append(
            {
                "id": id,
                "label": label,
                "start": start,
                "stop": stop,
                "length": length,
                "seq": seq,
            }
        )
    return feat


def nest_intervals(intervals):
    def nest(start_index, end_limit):
        nested = []

        i = start_index
        while i < len(intervals) and intervals[i]["start"] < end_limit:
            current_interval = intervals[i]
            child, next_index = nest(i + 1, current_interval["stop"])
            interval_obj = {
                "id": current_interval["id"],
                "label": current_interval["label"],
                "start": current_interval["start"],
                "stop": current_interval["stop"],
                "length": current_interval["length"],
                "seq": current_interval["seq"],
                "regions": child,
            }
            nested.append(interval_obj)
            i = next_index

        return nested, i

    result, _ = nest(0, intervals[0]["stop"])
    return result


def fill_gaps(seq, regions, parent_start=0, parent_stop=0):
    if len(regions) == 0:
        return []

    # Insert a filler at the start if necessary
    if regions[0]["start"] > parent_start:
        start = parent_start
        stop = regions[0]["start"]
        s = seq[start:stop]
        regions.insert(
            0,
            {
                "id": "filler_start",
                "label": "filler_start",
                "start": start,
                "stop": stop,
                "length": stop - start,
                "seq": s,
                "regions": [],
            },
        )

    new_regions = []
    for i, region in enumerate(regions):
        # Append the current region
        new_regions.append(region)

        # Recursive call for nested regions
        if "regions" in region:
            region["regions"] = fill_gaps(
                seq, region["regions"], region["start"], region["stop"]
            )

        # Check for gap and insert a filler
        if i < len(regions) - 1 and region["stop"] < regions[i + 1]["start"]:
            filler_id = f'filler_{region["id"]}_{regions[i+1]["id"]}'
            start = region["stop"]
            stop = regions[i + 1]["start"]
            s = seq[start:stop]
            new_regions.append(
                {
                    "id": filler_id,
                    "label": filler_id,
                    "start": start,
                    "stop": stop,
                    "length": stop - start,
                    "seq": s,
                    "regions": [],
                }
            )

    # Insert a filler at the end if necessary
    if new_regions[-1]["stop"] < parent_stop:
        start = new_regions[-1]["stop"]
        stop = parent_stop
        s = seq[start:stop]
        new_regions.append(
            {
                "id": "filler_end",
                "label": "filler_end",
                "start": start,
                "stop": stop,
                "length": stop - start,
                "seq": s,
                "regions": [],
            }
        )

    return new_regions


# convert filled regions to seqspec, must be recursive function
# regions is a list
def convert(regions):
    if len(regions) == 0:
        return []
    new_regions = []
    for r in regions:
        rgn = Region(
            r["id"],
            "",
            r["label"],
            "fixed",
            r["seq"],
            r["length"],
            r["length"],
            None,
            None,
        )
        if len(r["regions"]) > 0:
            rgn.regions = convert(r["regions"])
        new_regions.append(rgn)
    return new_regions

================
File: seqspec_index.py
================
from seqspec.utils import load_spec, map_read_id_to_regions
from seqspec.seqspec_find import run_find
from collections import defaultdict
from typing import Dict, List, Tuple
from argparse import SUPPRESS
import os
from seqspec.Region import RegionCoordinate, project_regions_to_coordinates, itx_read


def setup_index_args(parser):
    subparser = parser.add_parser(
        "index",
        description="index reads or regions in a seqspec file",
        help="index reads or regions in a seqspec file",
    )
    subparser_required = subparser.add_argument_group("required arguments")
    subparser.add_argument("yaml", help="Sequencing specification yaml file")
    subparser.add_argument(
        "-o",
        metavar="OUT",
        help=("Path to output file"),
        type=str,
        default=None,
    )

    subparser.add_argument(
        "-s",
        metavar="SUBREGIONTYPE",
        help=SUPPRESS,
        type=str,
        default=None,
    )

    subparser.add_argument(
        "-t",
        metavar="TOOL",
        help=("Tool"),
        default="tab",
        type=str,
        choices=["chromap", "kb", "seqkit", "simpleaf", "starsolo", "tab", "zumis"],
    )

    subparser.add_argument(
        "--rev", help="Returns 3'->5' region order", action="store_true"
    )

    # boolean to indicate specifying a region or a read
    subparser.add_argument(
        "--region",
        help="Specify a region",
        action="store_true",
    )
    subparser_required.add_argument(
        "-m",
        metavar="MODALITY",
        help=("Modality"),
        type=str,
        default=None,
        required=True,
    )
    subparser_required.add_argument(
        "-r",
        metavar="READ or REGION",
        help=("Read or Region"),
        type=str,
        default=None,
        required=True,
    )

    return subparser


def validate_index_args(parser, args):
    # if everything is valid the get_index
    # get paramters
    fn = args.yaml
    m = args.m
    r = args.r
    t = args.t
    o = args.o
    s = args.s
    rev = args.rev

    rgn = args.region

    # load spec
    spec = load_spec(fn)
    rds = r.split(",")
    # reads can be paths, take the basename of the path, use os

    rds = [os.path.basename(r) for r in rds]

    x = run_index(spec, m, rds, fmt=t, rev=rev, region=rgn, subregion_type=s)

    # post processing
    if o:
        with open(o, "w") as f:
            print(x, file=f)
    else:
        print(x)
    return


def run_index(
    spec, modality, reads, fmt="tab", rev=False, region=False, subregion_type=None
):
    FORMAT = {
        "chromap": format_chromap,
        "kb": format_kallisto_bus,
        "seqkit": format_seqkit_subseq,
        "simpleaf": format_simpleaf,
        "starsolo": format_starsolo,
        "tab": format_tab,
        "zumis": format_zumis,
    }
    indices = []
    for r in reads:
        if region:
            index = get_index(spec, modality, r, rev=rev)
        else:
            index = get_index_by_primer(spec, modality, r)
        indices.append(index)
    return FORMAT[fmt](indices, subregion_type)


# TODO: modify to use RegionCoordinate object
def get_index_by_type(
    spec, modality, region_id, rev=False
) -> Dict[str, List[Tuple[int, int]]]:
    rid = region_id
    # run function
    index = defaultdict(list)
    regions = run_find(spec, modality, rid)
    leaves = regions[0].get_leaves()
    if rev:
        leaves.reverse()
    cuts = project_regions_to_coordinates(leaves)

    # index is a legacy data structure, todo fix
    for c in cuts:
        index[c.start, c.stop] = c.region_type

    # groupby requested region
    for idx, l in enumerate(leaves):
        t = l.region_type
        c = cuts[idx]

        index[t].extend([c])
    return index


def get_index(
    spec, modality, region_id, rev=False
) -> Dict[str, List[RegionCoordinate]]:
    rid = region_id
    regions = run_find(spec, modality, rid)
    leaves = regions[0].get_leaves()
    if rev:
        leaves.reverse()
    cuts = project_regions_to_coordinates(leaves)

    return {region_id: cuts}


def get_index_by_primer(
    spec, modality: str, read_id: str
) -> Dict[str, List[RegionCoordinate]]:  # noqa
    # this manages the strandedness internally
    (read, rgns) = map_read_id_to_regions(spec, modality, read_id)

    # get the cuts for all of the atomic elements (tuples of 0-indexed start stop)
    rcs = project_regions_to_coordinates(rgns)

    new_rcs = itx_read(rcs, 0, read.max_len)

    return {read_id: new_rcs}


def format_kallisto_bus(indices, subregion_type=None):
    bcs = []
    umi = []
    feature = []
    for idx, region in enumerate(indices):
        for rgn, cuts in region.items():
            for cut in cuts:
                if cut.region_type.upper() == "BARCODE":
                    bcs.append(f"{idx},{cut.start},{cut.stop}")
                elif cut.region_type.upper() == "UMI":
                    umi.append(f"{idx},{cut.start},{cut.stop}")
                elif (
                    cut.region_type.upper() == "CDNA"
                    or cut.region_type.upper() == "GDNA"
                    or cut.region_type.upper() == "PROTEIN"
                    or cut.region_type.upper() == "TAG"
                ):
                    feature.append(f"{idx},{cut.start},{cut.stop}")
    if len(umi) == 0:
        umi.append("-1,-1,-1")
    if len(bcs) == 0:
        bcs.append("-1,-1,-1")

    x = ",".join(bcs) + ":" + ",".join(umi) + ":" + ",".join(feature)
    return x


# this one should only return one string
# TODO: return to this
def format_seqkit_subseq(indices, subregion_type=None):
    # The x string format is start:stop (1-indexed)
    # x = ""
    # region = indices[0]
    # # need to get the right start position
    x = ""
    region = indices[0]
    for rgn, cuts in region.items():
        for cut in cuts:
            if cut.region_type == subregion_type:
                x = f"{cut.start+1}:{cut.stop}\n"

    return x


def format_tab(indices, subregion_type=None):
    x = ""
    for idx, region in enumerate(indices):
        for rgn, cuts in region.items():
            for cut in cuts:
                x += f"{rgn}\t{cut.name}\t{cut.region_type}\t{cut.start}\t{cut.stop}\n"

    return x[:-1]


def format_starsolo(indices, subregion_type=None):
    bcs = []
    umi = []
    cdna = []
    for idx, region in enumerate(indices):
        for rgn, cuts in region.items():
            for cut in cuts:
                if cut.region_type.upper() == "BARCODE":
                    bcs.append(f"--soloCBstart {cut.start + 1} --soloCBlen {cut.stop}")
                elif cut.region_type.upper() == "UMI":
                    umi.append(
                        f"--soloUMIstart {cut.start + 1} --soloUMIlen {cut.stop - cut.start}"
                    )
                elif cut.region_type.upper() == "CDNA":
                    cdna.append(f"{cut.start},{cut.stop}")
    x = f"--soloType CB_UMI_Simple {bcs[0]} {umi[0]}"
    return x


def format_simpleaf(indices, subregion_type=None):
    x = ""
    xl = []
    for idx, region in enumerate(indices):
        fn = idx
        x = f"{fn+1}{{"
        for rgn, cuts in region.items():
            for cut in cuts:
                if cut.region_type.upper() == "BARCODE":
                    x += f"b[{cut.stop-cut.start}]"
                elif cut.region_type.upper() == "UMI":
                    x += f"u[{cut.stop-cut.start}]"
                elif cut.region_type.upper() == "CDNA":
                    x += f"r[{cut.stop - cut.start}]"
            x += "x:}"
        xl.append(x)
    return "".join(xl)


def format_zumis(indices, subregion_type=None):
    xl = []
    for idx, region in enumerate(indices):
        x = ""
        for rgn, cuts in region.items():
            for cut in cuts:
                if cut.region_type.upper() == "BARCODE":
                    x += f"- BCS({cut.start + 1}-{cut.stop})\n"
                elif cut.region_type.upper() == "UMI":
                    x += f"- UMI({cut.start + 1}-{cut.stop})\n"
                elif cut.region_type.upper() == "CDNA":
                    x += f"- cDNA({cut.start + 1}-{cut.stop})\n"
        xl.append(x)

    return "\n".join(xl)[:-1]


def format_chromap(indices, subregion_type=None):
    bc_fqs = []
    bc_str = []
    gdna_fqs = []
    gdna_str = []
    for idx, region in enumerate(indices):
        for rgn, cuts in region.items():
            for cut in cuts:
                if cut.region_type.upper() == "BARCODE":
                    bc_fqs.append(rgn)
                    bc_str.append(f"bc:{cut.start}:{cut.stop}")
                    pass
                elif cut.region_type.upper() == "GDNA":
                    gdna_fqs.append(rgn)
                    gdna_str.append(f"{cut.start}:{cut.stop}")
    if len(set(bc_fqs)) > 1:
        raise Exception("chromap only supports barcodes from one fastq")
    if len(set(gdna_fqs)) > 2:
        raise Exception("chromap only supports genomic dna from two fastqs")

    barcode_fq = bc_fqs[0]
    read1_fq = list(set(gdna_fqs))[0]
    read2_fq = list(set(gdna_fqs))[1]
    read_str = ",".join([f"r{idx}:{ele}" for idx, ele in enumerate(gdna_str, 1)])
    bc_str = ",".join(bc_str)

    cmap_str = f"-1 {read1_fq} -2 {read2_fq} --barcode {barcode_fq} --read-format {bc_str},{read_str}"

    return cmap_str


def format_splitcode(indices, subregion_type=None):
    pass

================
File: seqspec_info.py
================
from seqspec.utils import load_spec
import json


def setup_info_args(parser):
    subparser = parser.add_parser(
        "info",
        description="get info about seqspec file",
        help="get info about seqspec file",
    )

    subparser.add_argument("yaml", help="Sequencing specification yaml file")
    subparser.add_argument(
        "-o",
        metavar="OUT",
        help=("Path to output file"),
        type=str,
        default=None,
        required=False,
    )
    return subparser


def validate_info_args(parser, args):
    # if everything is valid the run_info
    fn = args.yaml
    o = args.o
    spec = load_spec(fn)
    info = run_info(spec)

    if o:
        with open(o, "w") as f:
            json.dump(info, f, sort_keys=False, indent=4)
    else:
        print(json.dumps(info, sort_keys=False, indent=4))


def run_info(spec):
    # return json of the Assay object
    info = spec.to_dict()
    del info["library_spec"]
    return info

================
File: seqspec_init.py
================
from seqspec.Assay import Assay
from seqspec.Region import Region
from typing import List
import newick

# example


# seqspec init -n myassay -m 1 -o spec.yaml "(((barcode:16,umi:12)r1.fastq.gz,(cdna:150)r2.fastq.gz)rna)"
# seqspec init -n myassay -m 2 -o spec.yaml "(((barcode:16,umi:12)r1.fastq.gz,(cdna:150)r2.fastq.gz)rna,((barcode:16)r1.fastq.gz,(gdna:150)r2.fastq.gz,(gdna:150)r3.fastq.gz)atac)"
def setup_init_args(parser):
    subparser = parser.add_parser(
        "init",
        description="init a seqspec file",
        help="init a seqspec file",
    )
    subparser_required = subparser.add_argument_group("required arguments")
    subparser_required.add_argument(
        "-n", metavar="NAME", type=str, help="assay name", required=True
    )
    subparser_required.add_argument(
        "-m", metavar="MODALITIES", type=int, help="number of modalities", required=True
    )

    subparser_required.add_argument(
        "-o",
        metavar="OUT",
        help=("Path to output file"),
        type=str,
        default=None,
        required=True,
    )
    subparser.add_argument("newick", help=("tree in newick format"))
    return subparser


def validate_init_args(parser, args):
    # if everything is valid the run_init
    name = args.n
    modalities = args.m
    newick_str = args.newick
    o = args.o
    if newick is None:
        raise ValueError("modality-FASTQs pairs must be provided")

    tree = newick.loads(newick_str)
    if len(tree[0].descendants) != modalities:
        raise ValueError(
            "Number of modalities must match number of modality-FASTQs pairs"
        )

    # load in two specs
    spec = run_init(name, tree[0].descendants)
    spec.to_YAML(o)


# takes in library_spec list of nodes
def run_init(name: str, tree: List[newick.Node]):
    # make regions for each fastq
    # make region for each modality
    # add fastq regions to modality regions
    # add modality regions to assay
    rgns = []
    mnames = []
    for t in tree:
        r = Region(region_id="", region_type="", name="", sequence_type="")
        rgns.append(newick_to_region(t, r))
        mnames.append(t.name)

    assay = Assay(
        assay="",
        sequencer="",
        name=name,
        doi="",
        publication_date="",
        description="",
        modalities=mnames,
        lib_struct="",
        library_spec=rgns,
    )

    return assay


# nw = "((barcode,umi)r1.fastq.gz,(cdna)r2.fastq.gz)rna;"
# wn = "rna(r1.fastq.gz(barcode,umi),r1.fastq.gz(cdna));"
# ex = {"rna": [{"r1.fastq.gz": [{"barcode": "barcode"}, {"umi": "umi"}]}, {"r2.fastq.gz": [{"cdna": "cdna"}]}]}
# tree = newick.loads(nw)
# print(tree[0].ascii_art())
# user writes newick format cli and gets an initialized spec file
def newick_to_region(
    node, region=Region(region_id="", region_type="", name="", sequence_type="")
):
    region.region_id = node.name
    region.name = node.name

    if len(node.descendants) == 0:
        region.min_len = int(node.length)
        region.max_len = int(node.length)
        return region
    region.regions = []
    for n in node.descendants:
        region.regions.append(
            newick_to_region(
                n,
                Region(region_id=n.name, region_type="", name=n.name, sequence_type=""),
            )
        )
    return region

================
File: seqspec_modify.py
================
from seqspec.utils import load_spec


def setup_modify_args(parser):
    # given a spec, a region id and a list of key value property pairs, modify the spec
    subparser = parser.add_parser(
        "modify",
        description="modify region attributes",
        help="modify region attributes",
    )
    subparser_required = subparser.add_argument_group("required arguments")
    subparser.add_argument("yaml", help="Sequencing specification yaml file")

    # Region properties

    subparser.add_argument(
        "--region-id",
        metavar="REGIONID",
        help=("New ID of region"),
        type=str,
        default=None,
    )
    subparser.add_argument(
        "--region-type",
        metavar="REGIONTYPE",
        help=("New type of region"),
        type=str,
        default=None,
    )
    subparser.add_argument(
        "--region-name",
        metavar="REGIONNAME",
        help=("New name of region"),
        type=str,
        default=None,
    )
    subparser.add_argument(
        "--sequence-type",
        metavar="SEQUENCETYPE",
        help=("New type of sequence"),
        type=str,
        default=None,
    )
    subparser.add_argument(
        "--sequence",
        metavar="SEQUENCE",
        help=("New sequence"),
        type=str,
        default=None,
    )
    subparser.add_argument(
        "--min-len",
        metavar="MINLEN",
        help=("Min region length"),
        type=int,
        default=None,
    )
    subparser.add_argument(
        "--max-len",
        metavar="MAXLEN",
        help=("Max region length"),
        type=int,
        default=None,
    )

    subparser_required.add_argument(
        "-o",
        metavar="OUT",
        help=("Path to output file"),
        type=str,
        default=None,
        required=True,
    )
    subparser_required.add_argument(
        "-r",
        metavar="REGIONID",
        help=("ID of region to modify"),
        type=str,
        default=None,
        required=True,
    )
    subparser_required.add_argument(
        "-m",
        metavar="MODALITY",
        help=("Modality of the assay"),
        type=str,
        default=None,
        required=True,
    )

    return subparser


def validate_modify_args(parser, args):
    # if everything is valid the run_format
    fn = args.yaml
    o = args.o
    spec = load_spec(fn)
    modality = args.m
    target_region = args.r

    region_id = args.region_id
    region_type = args.region_type
    region_name = args.region_name
    sequence_type = args.sequence_type
    sequence = args.sequence

    min_len = args.min_len
    max_len = args.max_len
    kwd = {
        "region_id": region_id,
        "region_type": region_type,
        "name": region_name,
        "sequence_type": sequence_type,
        "sequence": sequence,
        "min_len": min_len,
        "max_len": max_len,
    }
    spec = run_modify(spec, modality, target_region, **kwd)
    # update region in spec
    # once the region is updated, update the spec
    spec.update_spec()
    spec.to_YAML(o)


def run_modify(
    spec,
    modality,
    target_region,
    region_id,
    region_type,
    name,
    sequence_type,
    sequence,
    min_len,
    max_len,
):
    spec.get_libspec(modality).update_region_by_id(
        target_region,
        region_id,
        region_type,
        name,
        sequence_type,
        sequence,
        min_len,
        max_len,
    )

    return spec

================
File: seqspec_onlist.py
================
from seqspec.Assay import Assay
from seqspec.Region import project_regions_to_coordinates, itx_read, Onlist
from seqspec.utils import load_spec, map_read_id_to_regions
from seqspec.seqspec_find import run_find_by_type, run_find
import os
from seqspec.utils import read_list, find_onlist_file
import itertools
from typing import List


def setup_onlist_args(parser):
    subparser = parser.add_parser(
        "onlist",
        description="get onlist file for specific region",
        help="get onlist file for specific regions",
    )
    subparser_required = subparser.add_argument_group("required arguments")
    subparser.add_argument("yaml", help="Sequencing specification yaml file")
    subparser.add_argument(
        "-o",
        metavar="OUT",
        help=("Path to output file"),
        type=str,
        default=None,
    )
    format_choices = ["read", "region", "region-type"]
    subparser.add_argument(
        "-s",
        metavar="SPECOBJECT",
        type=str,
        default="read",
        choices=format_choices,
        help=f"Type of spec object ({', '.join(format_choices)}), default: region",
    )
    subparser_required.add_argument(
        "-m",
        metavar="MODALITY",
        help=("Modality"),
        type=str,
        default=None,
        required=True,
    )
    subparser_required.add_argument(
        "-r",
        metavar="READ or REGION",
        help=("Read or Region"),
        type=str,
        default=None,
        required=False,
    )
    format_choices = ["product", "multi"]
    subparser.add_argument(
        "-f",
        metavar="FORMAT",
        type=str,
        default="product",
        choices=format_choices,
        help=f"Format for combining multiple onlists ({', '.join(format_choices)}), default: product",
    )
    subparser.add_argument("--list", action="store_true", help=("List onlists"))
    return subparser


def validate_onlist_args(parser, args):
    # get paramters
    fn = args.yaml
    m = args.m
    r = args.r
    f = args.f
    # TODO: if onlist is a link, download. also fix output path
    # o = args.o
    # load spec
    spec = load_spec(fn)
    # if number of barcodes > 1 then we need to join them
    # note that in order to enable --list as an option we make regions optional but its
    # required for the standard onlist function
    if args.list:
        onlists = run_list_onlists(spec, m)
        for ol in onlists:
            print(f"{ol['region_id']}\t{ol['filename']}\t{ol['location']}\t{ol['md5']}")
        return
    if args.s == "region":
        olist = run_onlist_region(spec, m, r, f)
    elif args.s == "region-type":
        olist = run_onlist_region_type(spec, m, r, f)
    elif args.s == "read":
        olist = run_onlist_read(spec, m, r, f)
    print(os.path.join(os.path.dirname(os.path.abspath(fn)), olist))
    return


def run_onlist_region_type(spec: Assay, modality: str, region_type: str, fmt: str):
    # for now return the path to the onlist file for the modality/region pair

    # run function
    regions = run_find_by_type(spec, modality, region_type)
    onlists = []
    for r in regions:
        onlists.append(r.get_onlist())
    if len(onlists) == 0:
        raise ValueError(f"No onlist found for region type {region_type}")
    return join_onlists(onlists, fmt)


def run_onlist_region(spec: Assay, modality: str, region_id: str, fmt: str):
    # for now return the path to the onlist file for the modality/region pair

    # run function
    regions = run_find(spec, modality, region_id)
    onlists = []
    for r in regions:
        onlists.append(r.get_onlist())
    if len(onlists) == 0:
        raise ValueError(f"No onlist found for region {region_id}")
    return join_onlists(onlists, fmt)


def run_onlist_read(spec: Assay, modality: str, read_id: str, fmt: str):
    # for now return the path to the onlist file for the modality/region pair

    # run function
    (read, rgns) = map_read_id_to_regions(spec, modality, read_id)
    # convert regions to region coordinates
    rcs = project_regions_to_coordinates(rgns)
    # intersect read with region coordinates
    new_rcs = itx_read(rcs, 0, read.max_len)

    onlists = []
    for r in new_rcs:
        ol = r.get_onlist()
        if ol:
            onlists.append(ol)

    if len(onlists) == 0:
        raise ValueError(f"No onlist found for read {read_id}")

    return join_onlists(onlists, fmt)


def run_list_onlists(spec: Assay, modality: str):
    regions = spec.get_libspec(modality).get_onlist_regions()
    olsts = []
    for r in regions:
        olsts.append(
            {
                "region_id": r.region_id,
                "filename": r.onlist.filename,
                "location": r.onlist.location,
                "md5": r.onlist.md5,
            }
        )
    return olsts


def find_list_target_dir(onlists):
    for olst in onlists:
        if olst.location == "local":
            base_path = os.path.dirname(os.path.abspath(onlists[0].filename))
            if os.access(base_path, os.W_OK):
                return base_path

    return os.getcwd()


def join_onlists(onlists: List[Onlist], fmt: str):
    """Given a list of onlist objects return a file containing the combined list"""
    if len(onlists) == 0:
        print("No lists present")
        return

    # look to see if the barcode file is present.
    first_location, first_filename = find_onlist_file(onlists[0])
    if len(onlists) == 1 and first_location == "local":
        return first_filename
    else:
        base_path = find_list_target_dir(onlists)
        # join the onlists
        lsts = [read_list(o) for o in onlists]
        joined_path = os.path.join(base_path, "onlist_joined.txt")
        formatter_functions = {
            "product": join_product_onlist,
            "multi": join_multi_onlist,
        }
        formatter = formatter_functions.get(fmt)
        if formatter is None:
            raise ValueError(
                f"Unrecognized format type {fmt}. Expected {', '.join(list(formatter_functions.keys()))}"
            )

        with open(joined_path, "w") as f:
            for line in formatter(lsts):
                f.write(line)

        return joined_path


def join_product_onlist(lsts):
    for i in itertools.product(*lsts):
        yield f"{''.join(i)}\n"


def join_multi_onlist(lsts):
    for row in itertools.zip_longest(*lsts, fillvalue="-"):
        yield f"{' '.join((str(x) for x in row))}\n"

================
File: seqspec_print_html.py
================
from seqspec.Region import Region


def run_print_html(spec):
    # header = headerTemplate(spec.name, spec.doi, spec.description, spec.modalities)
    # header2 = "## Final Library"
    # library_spec = multiModalTemplate(spec.library_spec)
    # s = f"{header}\n{header2}\n{library_spec}"
    s = htmlTemplate(spec)
    return s


def headerTemplate(name, doi, description, modalities):
    s = f"""<h1 style="text-align: center">{name}</h1>
  <ul>
    <li>
      <a href="{doi}"
        >{doi}</a
      >
    </li>
    <li>
      {description}
    </li>
    <li>{", ".join(modalities)}</li>
  </ul>
    """
    return s


def colorSeq(regions):
    return "".join(
        [f"<{r.region_type}>{r.sequence}</{r.region_type}>" for r in regions]
    )


def atomicRegionTemplate(
    region: Region,
    name,
    region_type,
    sequence_type,
    sequence,
    min_len,
    max_len,
    onlist,
    regions,
):
    seq = (
        colorSeq(region.get_leaves())
        if regions
        else f"<{region_type}>{sequence}</{region_type}>"
    )
    onlist = f"{onlist.filename} (md5: {onlist.md5})" if onlist else None
    lst = []
    if regions:
        for idx, r in enumerate(regions):
            s = atomicRegionTemplate(
                r,
                r.region_id,
                r.region_type,
                r.sequence_type,
                r.sequence,
                r.min_len,
                r.max_len,
                r.onlist,
                r.regions,
            )
            lst.append(s)
        subseq = "</li><li>".join(lst)
        subseq = f"<ol><li>{subseq}</li></ol>"
    else:
        subseq = ""

    # subseq = "<li>" + "</li><li>".join( [  for i in regions if regions else ''])
    s = f"""<details>
    <summary>{name}</summary>
    <ul>
      <li>region_type: {region_type}</li>
      <li>sequence_type: {sequence_type}</li>
      <li>
        sequence:
        <pre
        style="
        overflow-x: auto;
        text-align: left;
        margin: 0;
        display: inline;
        "
        >
{seq}</pre
        >
      </li>
      <li>min_len: {min_len}</li>
      <li>max_len: {max_len}</li>
      <li>onlist: {onlist}</li>
      <li> regions: {subseq}
      </li>
  </details>
    """
    return s


def regionsTemplate(regions):
    s = f"""<ol><li>
    {'</li><li>'.join([atomicRegionTemplate(
                r,
                r.region_id,
                r.region_type,
                r.sequence_type,
                r.sequence,
                r.min_len,
                r.max_len,
                r.onlist,
                r.regions,
    ) for idx, r in enumerate(regions)])}
    </li></ol>"""
    return s


def libStructTemplate(region):
    s = f"""
  <h6 style="text-align: center">{region.name}</h6>
  <pre
    style="overflow-x: auto; text-align: left; background-color: #f6f8fa"
  >
{colorSeq(region.get_leaves())}</pre>
    """
    return s


def multiModalTemplate(library_spec):
    s = "".join(
        [libStructTemplate(v) + "\n" + regionsTemplate(v.regions) for v in library_spec]
    )
    return s


def htmlTemplate(spec):
    s = f"""
  <!DOCTYPE html>
  <html>
    <head>
      <meta name="viewport" content="width=device-width, initial-scale=1" />
      <style>
      highlight {{
      color: green;
      }}

      illumina_p5 {{color:#08519c;}}
      illumina_p7 {{color:#a50f15;}}
      nextera_read1 {{color:#bcbddc;}}
      nextera_read2 {{color:#9ebcda;}}
      truseq_read1 {{color:#4a1486;}}
      truseq_read2 {{color:#6a51a3;}}
      ME {{color:#969696;}}
      s5 {{color:#6baed6;}}
      s7 {{color:#fc9272;}}
      barcode {{color:#f768a1;}}
      umi {{color:#807dba;}}
      gDNA {{color:#f03b20;}}
    cDNA {{color:#7e331f;}}
      </style>
    </head>
    <body>
      <div style="width: 75%; margin: 0 auto">
        <h6><a href="../../index.html">Back</a></h6>
        <div id="assay">
          {headerTemplate(
            spec.name,
            spec.doi,
            spec.description,
            spec.modalities
          )}
        </div>
        <div id="library_spec">
          <h2>Final library</h2>
          {multiModalTemplate(spec.library_spec)}
        </div>
      </div>
    </body>
  </html>
    """
    return s

================
File: seqspec_print.py
================
from seqspec.utils import load_spec
from seqspec.seqspec_print_html import run_print_html
import newick
from .utils import REGION_TYPE_COLORS, complement_sequence
from seqspec.Region import project_regions_to_coordinates


def setup_print_args(parser):
    subparser = parser.add_parser(
        "print",
        description="print seqspec file",
        help="print seqspec file",
    )
    subparser.add_argument("yaml", help="Sequencing specification yaml file")
    subparser.add_argument(
        "-o",
        metavar="OUT",
        help=("Path to output file"),
        type=str,
        default=None,
    )

    format_choices = ["library", "sequence", "libseq"]
    subparser.add_argument(
        "-s",
        metavar="SPEC",
        help=(
            f"Specification to print ({', '.join(format_choices)}), default: library"
        ),
        type=str,
        default="library",
        choices=format_choices,
    )
    # TODO: fix naming convention: sequence -> seqspec,
    # add libspec (list of regions tab delimited)
    # change tree -> libspec-tree
    #
    # actually, add -s which clarifies which spec to print (library or sequence)
    # then -f should have tree, png, html, sequence
    format_choices = ["tree", "html", "png", "sequence", "info"]
    subparser.add_argument(
        "-f",
        metavar="FORMAT",
        help=(f"Format ({', '.join(format_choices)}), default: tree"),
        type=str,
        default="tree",
        choices=format_choices,
    )

    return subparser


def validate_print_args(parser, args):
    # if everything is valid the run_print
    fmt = args.f
    spectype = args.s

    # validate fmt and spectype pairs, only some are valid
    if fmt == "png" and spectype != "library":
        raise ValueError("-f png only valid for -s library")
    if fmt == "tree" and spectype != "library":
        raise ValueError("-f tree only valid for -s library")
    if fmt == "html" and spectype != "library":
        raise ValueError("-f html only valid for -s library")
    if fmt == "info" and spectype != "sequence":
        raise ValueError("-f info only valid for -s sequence")
    if fmt == "sequence" and spectype != "libseq":
        raise ValueError("-f sequence only valid for -s libseq")

    fn = args.yaml
    o = args.o
    spec = load_spec(fn)

    LIBSEQ_CMD = {
        "sequence": run_print_libseq_sequence,
    }

    SEQUENCE_CMD = {
        "info": run_print_sequence_spec,
    }
    LIBRARY_CMD = {
        "tree": run_print_library_tree,
        "html": run_print_html,
        "png": run_print_library_png,
    }
    CMD = {
        "library": LIBRARY_CMD,
        "sequence": SEQUENCE_CMD,
        "libseq": LIBSEQ_CMD,
    }

    s = CMD[spectype][fmt](spec)
    if fmt == "png":
        s.savefig(o, dpi=300, bbox_inches="tight")
        return
    if o:
        with open(o, "w") as f:
            print(s, file=f)
    else:
        print(s)


def run_print_libseq_sequence(spec):
    p = []
    for modality in spec.modalities:
        p.append(libseq(spec, modality))
    return "\n".join(p)


def libseq(spec, modality):
    libspec = spec.get_libspec(modality)
    seqspec = spec.get_seqspec(modality)

    p = []
    n = []
    leaves = libspec.get_leaves()
    cuts = project_regions_to_coordinates(leaves)
    for idx, read in enumerate(seqspec, 1):
        read_len = read.max_len
        read_id = read.read_id
        primer_id = read.primer_id
        primer_idx = [i for i, l in enumerate(leaves) if l.region_id == primer_id][0]
        primer_pos = cuts[primer_idx]
        if read.strand == "pos":
            wsl = primer_pos.stop - 1
            ws = wsl * " "

            arrowl = read_len - 1
            arrow = arrowl * "-"

            p.append(f"{ws}|{arrow}>({idx}) {read_id}")
        elif read.strand == "neg":
            wsl = primer_pos.start - read_len
            ws = wsl * " "

            arrowl = read_len - 1
            arrow = arrowl * "-"

            n.append(f"{ws}<{arrow}|({idx}) {read_id}")

    s = "\n".join(
        [
            modality,
            "---",
            "\n".join(p),
            libspec.sequence,
            complement_sequence(libspec.sequence),
            "\n".join(n),
        ]
    )
    return s


def run_print(data):
    header = headerTemplate(data.name, data.doi, data.description, data.modalities)
    header2 = "## Final Library"
    library_spec = multiModalTemplate(data.library_spec)
    s = f"{header}\n{header2}\n{library_spec}"
    return s


def run_print_sequence_spec(spec):
    p = []
    for r in spec.sequence_spec:
        p.append(
            "\t".join(
                [r.read_id, r.primer_id, r.strand, str(r.min_len), str(r.max_len)]
            )
        )
    return "\n".join(p)


def run_print_library_tree(spec):
    t = []
    for r in spec.library_spec:
        t.append(r.to_newick())
    n = ",".join(t)
    # print(n)
    tree = newick.loads(f"({n})")
    return tree[0].ascii_art()


def argsort(arr):
    # http://stackoverflow.com/questions/3382352/equivalent-of-numpy-argsort-in-basic-python/3382369#3382369
    # by unutbu
    return sorted(range(len(arr)), key=arr.__getitem__)


def run_print_library_png(spec):
    # builds directly off of https://colab.research.google.com/drive/1ZCIGrwLEIfE0yo33bP8uscUNPEn1p1DH developed by https://github.com/LucasSilvaFerreira

    # modality
    modalities = spec.list_modalities()
    modes = [spec.get_libspec(m) for m in modalities]
    lengths = [i.min_len for i in modes]
    nmodes = len(modalities)

    # sort the modalities by their lengths
    asort = argsort(lengths)
    modalities = [modalities[i] for i in asort]
    lengths = [lengths[i] for i in asort]
    modes = [modes[i] for i in asort]
    assay_id = spec.assay_id

    fig, _ = plot_png(assay_id, modalities, modes, nmodes, lengths)
    return fig


def plot_png(assay, modalities, modes, nmodes, lengths):
    import matplotlib.pyplot as plt
    from matplotlib.patches import Rectangle
    import matplotlib.patches as mpatches

    fsize = 15
    plt.rcParams.update({"font.size": fsize})

    fig, ax = plt.subplots(
        figsize=(10, 1 * nmodes), nrows=nmodes, constrained_layout=True
    )
    fig.suptitle(assay)
    rts = []
    for m, ax in zip(modes, fig.get_axes()):
        # get leaves
        leaves = m.get_leaves()

        # setup plotting variables
        y = 0
        x = 0
        height = 1

        for idx, node in enumerate(leaves):
            # region tupe
            rtype = node.region_type.lower()
            # add to the global list so we can make a legend
            rts.append(rtype)
            # get region properties
            length = node.min_len
            label = f"{length}"

            # setup rectangle for the region
            rectangle = Rectangle(
                (x, y), length, height, color=REGION_TYPE_COLORS[rtype], ec="black"
            )

            # write in the length of the region in the rectangle
            ax.text(
                x + length / 2,
                y + height / 2,
                label,
                horizontalalignment="center",
                verticalalignment="center",
            )  # , rotation=90)
            # add the rectangle
            ax.add_patch(rectangle)

            # add length to x for next region
            x += length

        ax.autoscale()

        # since all axes use the same scale, set the xlim to be 0 to the max length
        ax.set(**{"xlim": (0, max(lengths))})

        # hide the spines
        for spine in ["right", "top", "left", "bottom"]:
            ax.spines[spine].set_visible(False)
        # Hide the axis and ticks and labels
        ax.xaxis.set_visible(False)
        ax.set_yticklabels([])
        ax.set_yticks([])

        # label the modality on the ylabel
        ax.set_ylabel(m.region_type, rotation=0, fontsize=20, ha="right", va="center")

    # adjust the xaxis for the last modality to show the length
    ax.xaxis.set_visible(True)
    ax.spines["bottom"].set_visible(True)
    ax.minorticks_on()

    ax.set(
        **{
            "xlabel": "# nucleotides",
        }
    )

    # setup the figure legend
    handles = []
    for t in sorted(set(rts)):
        handles.append(mpatches.Patch(color=REGION_TYPE_COLORS[t], label=t))
    fig.legend(handles=handles, loc="center", bbox_to_anchor=(1.1, 0.55))
    return (fig, ax)


def headerTemplate(name, doi, description, modalities):
    s = f"""# {name}
- DOI: [{doi}]({doi})
- Description: {description}
- Modalities: {", ".join(modalities)}
    """
    return s


def atomicRegionTemplate(
    name, region_type, sequence_type, sequence, min_len, max_len, onlist, ns=0
):
    s = f"""<details><summary>{name}</summary>

{' '*ns}- region_type: {region_type}
{' '*ns}- sequence_type: {sequence_type}
{' '*ns}- sequence: <pre style="overflow-x: auto; text-align: left; margin: 0; display: inline;">{sequence}</pre>
{' '*ns}- min_len: {min_len}
{' '*ns}- max_len: {max_len}
{' '*ns}- onlist: {onlist}
{' '*ns}</details>"""
    return s


def regionsTemplate(regions):
    s = "\n".join(
        [
            f"{idx + 1}. "
            + atomicRegionTemplate(
                v.name,
                v.region_type,
                v.sequence_type,
                v.sequence,
                v.min_len,
                v.max_len,
                v.onlist,
                len(str(idx + 1))
                + 1
                + 1,  # length of string rep of number plus 1 for "." plus 1 for space
            )
            for idx, v in enumerate(regions)
        ]
    )
    return s


def libStructTemplate(region):
    s = f"""###### {region.name}
<pre style="overflow-x: auto; text-align: left; background-color: #f6f8fa">{region.sequence}</pre>"""
    return s


def multiModalTemplate(library_spec):
    s = "\n".join(
        [libStructTemplate(v) + "\n" + regionsTemplate(v.regions) for v in library_spec]
    )
    return s

================
File: seqspec_split.py
================
import os
from seqspec.utils import load_spec
from seqspec.Assay import Assay


def setup_split_args(parser):
    subparser = parser.add_parser(
        "split",
        description="split seqspec file into modalities",
        help="split seqspec into modalities",
    )
    subparser_required = subparser.add_argument_group("required arguments")

    subparser.add_argument("yaml", help="Sequencing specification yaml file")
    subparser_required.add_argument(
        "-o",
        metavar="OUT",
        help=("Path to output file"),
        type=str,
        default=None,
        required=True,
    )
    return subparser


def validate_split_args(parser, args):
    # if everything is valid the run_split
    fn = args.yaml
    o = args.o
    spec = load_spec(fn)
    modalities = spec.list_modalities()
    # make a new spec per modality
    for m in modalities:
        spec_m = Assay(
            spec.assay,
            spec.sequencer,
            spec.name,
            spec.doi,
            spec.publication_date,
            spec.description,
            [m],
            spec.lib_struct,
            [spec.get_libspec(m)],
            spec.seqspec_version,
        )
        spec_m.update_spec()
        base_o = "spec." if os.path.basename(o) == "" else f"{os.path.basename(o)}."

        spec_m.to_YAML(os.path.join(os.path.dirname(o), f"{base_o}{m}.yaml"))


def run_split(spec):
    pass

================
File: seqspec_version.py
================
from seqspec.utils import load_spec
from . import __version__


def setup_version_args(parser):
    subparser = parser.add_parser(
        "version",
        description="Get seqspec version and seqspec file version",
        help="Get seqspec version and seqspec file version",
    )

    subparser.add_argument("yaml", help="Sequencing specification yaml file")
    subparser.add_argument(
        "-o",
        metavar="OUT",
        help=("Path to output file"),
        type=str,
        default=None,
    )
    return subparser


def validate_version_args(parser, args):
    # if everything is valid the run_version
    fn = args.yaml
    o = args.o
    spec = load_spec(fn)
    version = spec.seqspec_version
    tool_version = __version__
    s = f"seqspec version: {tool_version}\nseqspec file version: {version}"
    if o:
        with open(o, "w") as f:
            print(s, file=f)
    else:
        print(s)


def run_version(spec):
    pass

================
File: utils.py
================
import io
import os
import gzip
from pathlib import Path
from seqspec.Assay import Assay
from seqspec.Region import Onlist
from urllib.parse import urlparse
import yaml
import requests
from Bio import GenBank


def load_spec(spec_fn: str):
    with open(spec_fn, "r") as stream:
        return load_spec_stream(stream)


def load_spec_stream(spec_stream: io.IOBase):
    data: Assay = yaml.load(spec_stream, Loader=yaml.Loader)
    # set the parent id in the Assay object upon loading it
    for r in data.library_spec:
        r.set_parent_id(None)
    return data


def load_genbank(gbk_fn: str):
    with open(gbk_fn, "r") as stream:
        return load_genbank_stream(stream)


def load_genbank_stream(gbk_stream: io.IOBase):
    data: GenBank = GenBank.read(gbk_stream)
    return data


class RegionCoordinate:
    def __init__(self, cut_name, cut_type, start, end):
        self.cut_name = cut_name
        self.cut_type = cut_type
        self.start = start
        self.end = end

    def __repr__(self):
        return f"RegionCoordinate {self.cut_name} [{self.cut_type}]: ({self.start}, {self.end})"

    def __str__(self):
        return f"RegionCoordinate {self.cut_name} [{self.cut_type}]: ({self.start}, {self.end})"

    def __eq__(self, other):
        return self.start == other.start and self.end == other.end


def write_read(header, seq, qual, f):
    f.write(f"{header}\n{seq}\n+\n{qual}\n")


def yield_onlist_contents(stream):
    for line in stream:
        yield line.strip().split()[0]


def read_list(onlist: Onlist):
    """Given an onlist object read the local or remote data
    """
    location, filename = find_onlist_file(onlist)

    stream = None
    try:
        # open stream
        if location == "remote":
            auth = get_remote_auth_token()
            response = requests.get(filename, stream=True, auth=auth)
            response.raise_for_status()
            stream = response.raw
        elif location == "local":
            stream = open(filename, "rb")
        else:
            raise ValueError(
                "Unsupported location {}. Expected remote or local".format(location))

        # do we need to decompress?
        if filename.endswith(".gz"):
            stream = gzip.GzipFile(fileobj=stream)

        # convert to text stream
        stream = io.TextIOWrapper(stream)

        results = list(yield_onlist_contents(stream))
    finally:
        if stream is None:
            print("Warning: unable to open barcode file {}".format(filename))
        else:
            stream.close()

    return results


def find_onlist_file(onlist: Onlist):
    url = urlparse(onlist.filename)
    pathname = Path(url.path)
    basename = Path(pathname.name)
    if basename.exists():
        # we have a copy of the file in this directory
        return ("local", str(basename))
    elif pathname.exists():
        # we have a path to another directory
        return ("local", str(pathname))
    elif url.scheme != '' and onlist.location == "remote":
        # Should we ignore the location if there's a url scheme?
        return ("remote", str(onlist.filename))
    else:
        raise FileNotFoundError(
            "No such {} file {}".format(onlist.location, onlist.filename))


def get_remote_auth_token():
    """Look for authentication tokens for accessing remote resources
    """
    username = os.environ.get("IGVF_API_KEY")
    password = os.environ.get("IGVF_SECRET_KEY")
    if not (username is None or password is None):
        auth = (username, password)
    else:
        auth = None

    return auth


def region_ids_in_spec(seqspec, modality, region_ids):
    # return True if all region_ids are in seqspec
    spec = seqspec.get_libspec(modality)
    found = []
    for region_id in region_ids:
        found += [r.region_id for r in spec.get_region_by_id(region_id)]
    return found


def file_exists(uri):
    try:
        r = requests.head(uri)
        return r.status_code == 200
    except requests.ConnectionError:
        return False


REGION_TYPE_COLORS = {
    "barcode": "#2980B9",
    "cdna": "#8E44AD",
    "custom_primer": "#3CB371",
    "fastq": "#F1C40F",
    "gdna": "#E67E22",
    "illumina_p5": "#E17A47",
    "illumina_p7": "#E17A47",
    "index5": "#4AB19D",
    "index7": "#4AB19D",
    "linker": "#1ABC9C",
    "me1": "#E74C3C",
    "me2": "#E74C3C",
    "nextera_read1": "#FF8000",
    "nextera_read2": "#FF8000",
    "poly_a": "#FF0000",
    "poly_g": "#C0C0C0",
    "poly_t": "#7F8C8D",
    "poly_c": "#2C3E50",
    "s5": "#EF3D59",
    "s7": "#EF3D59",
    "truseq_read1": "#EFC958",
    "truseq_read2": "#EFC958",
    "umi": "#16A085",
    "tag": "#344E5C",
    "protein": "#ECF0F1",
}


# unused
# '#FF8C00'
# '#95A5A6'


def complement_nucleotide(nucleotide):
    complements = {
        "A": "T",
        "T": "A",
        "G": "C",
        "C": "G",
        "R": "Y",
        "Y": "R",
        "S": "S",
        "W": "W",
        "K": "M",
        "M": "K",
        "B": "V",
        "D": "H",
        "V": "B",
        "H": "D",
        "N": "N",
        "X": "X",
    }
    return complements.get(
        nucleotide, "N"
    )  # Default to 'N' if nucleotide is not recognized


def complement_sequence(sequence):
    return "".join(complement_nucleotide(n) for n in sequence.upper())


def map_read_id_to_regions(spec, modality, region_id):
    # get all atomic elements from library
    leaves = spec.get_libspec(modality).get_leaves()
    # get the read object and primer id
    read = [i for i in spec.sequence_spec if i.read_id == region_id][0]
    primer_id = read.primer_id
    # get the index of the primer in the list of leaves (ASSUMPTION, 5'->3' and primer is an atomic element)
    primer_idx = [i for i, l in enumerate(leaves) if l.region_id == primer_id][0]
    # If we are on the opposite strand, we go in the opposite way
    if read.strand == "neg":
        rgns = leaves[:primer_idx][::-1]
    else:
        rgns = leaves[primer_idx + 1 :]

    return (read, rgns)
